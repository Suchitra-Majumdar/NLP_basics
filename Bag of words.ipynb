{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2730a382",
   "metadata": {},
   "source": [
    "A bag-of-words is a representation of text that describes the occurrence of words within a document. It involves two things:\n",
    "\n",
    "A vocabulary of known words.\n",
    "A measure of the presence of known words.\n",
    "\n",
    "\n",
    "It is called a bag-of-words , because any information about the order or structure of words in the document is discarded. The model is only concerned with whether known words occur in the document, not where in the document. The complexity comes both in deciding how to design the vocabulary of known words (or tokens) and how to score the presence of known words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b45f23f",
   "metadata": {},
   "source": [
    "Bag-of-Words Model in SkLearn\n",
    "\n",
    "Design the Vocabulary \n",
    "\n",
    "\n",
    "Make a list of all of the words in our model vocabulary. The CountVectorizer provides a simple way to tokenize a collection of text documents and build a vocabulary of known words.\n",
    "\n",
    "Create an instance of the CountVectorizer class.\n",
    "Call the fit() function in order to learn a vocabulary from one or more documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05c43f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'best', 'foolishness', 'it', 'of', 'the', 'times', 'was', 'wisdom', 'worst']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Multiple documents\n",
    "text = [\"It was the best of times\", \"it was the worst of times\", \"it was the age of wisdom\", \"it was the age of foolishness\"] \n",
    "# create the transform\n",
    "vectorizer = CountVectorizer()\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(text)\n",
    "# summarize\n",
    "print(sorted(vectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c173ba",
   "metadata": {},
   "source": [
    "That is a vocabulary of 10 words from a corpus containing 24 words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b080d3ac",
   "metadata": {},
   "source": [
    "Create Document Vectors \n",
    "Document Vectors with CountVectorizer \n",
    "Next step is to score the words in each document. Because we know the vocabulary has 10 words, we can use a fixed-length document representation of 10, with one position in the vector to score each word. The simplest scoring method is to mark the presence of words as a boolean value, 0 for absent, 1 for present.\n",
    "\n",
    "Call the transform() function on one or more documents as needed to encode each as a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c531d9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 10)\n",
      "[[0 1 0 1 1 1 1 1 0 0]\n",
      " [0 0 0 1 1 1 1 1 0 1]\n",
      " [1 0 0 1 1 1 0 1 1 0]\n",
      " [1 0 1 1 1 1 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# encode document\n",
    "vector = vectorizer.transform(text)\n",
    "# summarize encoded vector\n",
    "print(vector.shape)\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ede52c",
   "metadata": {},
   "source": [
    "The same vectorizer can be used on documents that contain words not included in the vocabulary. These words are ignored and no count is given in the resulting vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdbbca94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 3 1 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# encode another document\n",
    "text2 = [\"the the the times\"]\n",
    "vector = vectorizer.transform(text2)\n",
    "print(vector.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ab2cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
